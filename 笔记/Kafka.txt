1. Kafka设计的目标是一个能处理大规模日志的消息系统。

2. 传统的消息系统在保证消息投递的准确性上，做了很多事情，消耗了很多性能。但是在大规模日志的场景下，丢失消息是可以接收的，Kafka通过牺牲一些准确性来获得更高的性能。

3. 传统的消息系统没有关注在高额的吞吐量上，比如JMS没有提供批量投递消息的API，导致每发送一条消息都需要经过一次完整的TCP/IP连接。

4. 传统的消息系统认为消息会立刻被消费，所以对消息积压的支持很弱。能积压的消息量很少，而且一旦出现积压，性能会大幅降低。

5. 消费者拉消息的模型，好处是能根据消费的速度拉消息，不会因为消息过多，处理不过来，导致消费者崩溃。

6. Kafka的消息存储在本地文件里，增加消息，就是往文件的末尾追加数据，当文件达到1GB的时候，创建新的文件继续存储。

7. Kafka在内存中保存每个消息文件的第一条消息的偏移量作为索引，消费者根据消息的偏移量，就能定位到消息在那个文件夹里。

8. Kafka不会显示地在内存里缓存消息，只使用文件系统的PageCache能力，避免重复缓存相同的数据，也能减少JVM的GC的开销。

9. 消费者和生产者都在读取消息文件，由于消费者总是稍微落后于生产者，所以能非常好地利用文件系统的缓存功能。

10. 将消息从文件经过网络传递给消费者，Kafka也做了性能优化，也就是所谓的零拷贝。
    普通的流程是文件 -> 操作系统的PageCache -> 应用缓存 -> 内核缓存 -> socket，需要四次数据拷贝。
    Kafka使用Unix提供的sendFile api减少了数据拷贝的次数，将PageCache的数据直接传递到socket。

11. 消费者的消费进度是维护在消费者端的，这样做的好处是消费者可以随时回退，从之前的任意时间点开始消费。
    这种方式对类似ETL的数据处理场景非常有用，消费逻辑出现bug，修复bug以后可以再从之前的点位开始重新消费。

12. partition是消息的最小合集，一个partition只允许一个消费者消费，为了保持负载均衡，通常partition的数量会远超消费者。

13. Kafka没有主节点的概念，设计时认为使用主节点会引入复杂性。依赖Zookeeper作为协调者。

14. Zookeeper存储了broker和consumer的节点列表，当发生改变时，会触发rebalance。

15. Zookeeper还存储了每一个partition的消费偏移量。

16. broker和consumer节点变化后，会触发rebalance，consumer需要重新选择消费的partition。
    a.丢弃当前消费的partition
    b.从Zookeeper读取最新的broker和consumer信息
    c.获取主题下的所有可用的partition列表
    d.获取主题下的所有consumer列表
    e.将partition列表和consumer列表排序
    f.j是当前消费者在consumer列表中的位置
    g.N是partition数量除以consumer数量的值
    h.选择j*N ~ ((j+1)*N)-1的范围的partition，分配给自己
    i.更新Zookeeper里的消费数据
    j.从Zookeeper里存储的最近消费偏移量开始，消费消息